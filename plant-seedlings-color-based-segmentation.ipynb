{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\n%env JOBLIB_TEMP_FOLDER=/tmp\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib import cm\nfrom matplotlib import colors\nimport seaborn as sns\nsns.set_style('whitegrid')\n\nfrom PIL import Image\nfrom imageio import imread\nimport imageio\nimport skimage\nimport skimage.io\nimport skimage.transform\nfrom imageio import imread\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import accuracy_score\n\nfrom skimage.morphology import closing, disk, opening\nimport random\nimport time\nimport copy\nfrom tqdm import tqdm_notebook as tqdm\nfrom os import listdir\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.models import Sequential\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.models import Model\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense, Flatten\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.core import Dropout\nfrom keras.layers.convolutional import *\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.applications.inception_v3 import decode_predictions\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom keras.models import model_from_json\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom keras import optimizers\nfrom keras.models import Sequential, Model \nfrom keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom keras.utils import np_utils\nfrom keras.optimizers import SGD\n\nfrom IPython.core.display import display, HTML\nfrom PIL import Image\nfrom io import BytesIO\nimport base64\n\nfrom os import listdir\nfrom skimage.segmentation import mark_boundaries\n\nimport cv2\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-27T08:52:21.766489Z","iopub.execute_input":"2021-05-27T08:52:21.767038Z","iopub.status.idle":"2021-05-27T08:52:35.653986Z","shell.execute_reply.started":"2021-05-27T08:52:21.766968Z","shell.execute_reply":"2021-05-27T08:52:35.65298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Directory='../input/v2-plant-seedlings-dataset/nonsegmentedv2/'\nsubfolders = listdir(Directory)\nprint(os.listdir('../input/v2-plant-seedlings-dataset/nonsegmentedv2/'))","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-27T08:52:35.656266Z","iopub.execute_input":"2021-05-27T08:52:35.656545Z","iopub.status.idle":"2021-05-27T08:52:35.670816Z","shell.execute_reply.started":"2021-05-27T08:52:35.656499Z","shell.execute_reply":"2021-05-27T08:52:35.669915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sfc=\"Small-flowered Cranesbill\"\nplt.figure(figsize=(15,12))\n\nfor n in range(12):\n        folder=subfolders[n]\n        plt.subplot(3,4,n+1)\n        files = listdir(Directory + folder + \"/\") \n        image=cv2.imread(Directory + folder + \"/\" + files[n+221])\n        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n        plt.axis(\"off\")\n        plt.title(folder, fontsize=14, weight='bold')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-27T08:52:35.675113Z","iopub.execute_input":"2021-05-27T08:52:35.675384Z","iopub.status.idle":"2021-05-27T08:52:37.515017Z","shell.execute_reply.started":"2021-05-27T08:52:35.675347Z","shell.execute_reply":"2021-05-27T08:52:37.514057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p1 = cv2.imread('/kaggle/input/v2-plant-seedlings-dataset/nonsegmentedv2/Small-flowered Cranesbill/135.png')\np1 = cv2.cvtColor(p1, cv2.COLOR_BGR2RGB)\nplt.imshow(p1)\nplt.grid(False)\nplt.show()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-05-27T08:52:37.516548Z","iopub.execute_input":"2021-05-27T08:52:37.517108Z","iopub.status.idle":"2021-05-27T08:52:37.867194Z","shell.execute_reply.started":"2021-05-27T08:52:37.517053Z","shell.execute_reply":"2021-05-27T08:52:37.86604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_size(w,h, ax=None):\n    \"\"\" w, h: width, height in inches \"\"\"\n    if not ax: ax=plt.gca()\n    l = ax.figure.subplotpars.left\n    r = ax.figure.subplotpars.right\n    t = ax.figure.subplotpars.top\n    b = ax.figure.subplotpars.bottom\n    figw = float(w)/(r-l)\n    figh = float(h)/(t-b)\n    ax.figure.set_size_inches(figw, figh)\n    \npixel_colors = p1.reshape((np.shape(p1)[0]*np.shape(p1)[1], 3))\nnorm = colors.Normalize(vmin=-1.,vmax=1.)\nnorm.autoscale(pixel_colors)\npixel_colors = norm(pixel_colors).tolist()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:52:37.871938Z","iopub.execute_input":"2021-05-27T08:52:37.872424Z","iopub.status.idle":"2021-05-27T08:52:38.622526Z","shell.execute_reply.started":"2021-05-27T08:52:37.872335Z","shell.execute_reply":"2021-05-27T08:52:38.621354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r, g, b = cv2.split(p1)\nfig = plt.figure()\naxis = fig.add_subplot(1, 1, 1, projection=\"3d\")\nset_size(6,6)\npixel_colors = p1.reshape((np.shape(p1)[0]*np.shape(p1)[1], 3))\nnorm = colors.Normalize(vmin=-1.,vmax=1.)\nnorm.autoscale(pixel_colors)\npixel_colors = norm(pixel_colors).tolist()\n\naxis.scatter(r.flatten(), g.flatten(), b.flatten(), facecolors=pixel_colors, marker=\".\")\naxis.set_xlabel(\"Red\", weight='bold')\naxis.set_ylabel(\"Green\", weight='bold')\naxis.set_zlabel(\"Blue\", weight='bold')\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-27T08:52:38.624355Z","iopub.execute_input":"2021-05-27T08:52:38.624728Z","iopub.status.idle":"2021-05-27T08:53:48.544131Z","shell.execute_reply.started":"2021-05-27T08:52:38.624666Z","shell.execute_reply":"2021-05-27T08:53:48.542939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hsv_p1 = cv2.cvtColor(p1, cv2.COLOR_RGB2HSV)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:53:48.545509Z","iopub.execute_input":"2021-05-27T08:53:48.54582Z","iopub.status.idle":"2021-05-27T08:53:48.553636Z","shell.execute_reply.started":"2021-05-27T08:53:48.545762Z","shell.execute_reply":"2021-05-27T08:53:48.552495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h, s, v = cv2.split(hsv_p1)\nfig = plt.figure()\naxis = fig.add_subplot(1, 1, 1, projection=\"3d\")\n\n\naxis.scatter(h.flatten(), s.flatten(), v.flatten(), facecolors=pixel_colors, marker=\".\")\naxis.set_xlabel(\"Hue\",weight='bold')\naxis.set_ylabel(\"Saturation\", weight='bold')\naxis.set_zlabel(\"Value\", weight='bold')\nset_size(6,6)\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-27T08:53:48.555006Z","iopub.execute_input":"2021-05-27T08:53:48.555288Z","iopub.status.idle":"2021-05-27T08:54:57.920323Z","shell.execute_reply.started":"2021-05-27T08:53:48.555235Z","shell.execute_reply":"2021-05-27T08:54:57.919582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_mask(image, colormin, colormax):\n        hsv_p1 = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)   \n        mask = cv2.inRange(hsv_p1, colormin , colormax)\n        result = cv2.bitwise_and(image, image, mask=mask)\n        plt.figure(figsize=(15,10))\n        plt.subplot(1, 3, 1)\n        plt.imshow(image)\n        plt.grid(False)\n        plt.subplot(1, 3, 2)\n        plt.imshow(mask, cmap=\"gray\")\n        plt.grid(False)\n        plt.subplot(1, 3, 3)\n        plt.imshow(result)\n        plt.grid(False)\n        return plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:54:57.921491Z","iopub.execute_input":"2021-05-27T08:54:57.92189Z","iopub.status.idle":"2021-05-27T08:54:57.929677Z","shell.execute_reply.started":"2021-05-27T08:54:57.921836Z","shell.execute_reply":"2021-05-27T08:54:57.928989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colormin=(36, 25, 25)\ncolormax=(70, 255,255)\n\nplot_mask(p1, colormin, colormax)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-27T08:54:57.931067Z","iopub.execute_input":"2021-05-27T08:54:57.931742Z","iopub.status.idle":"2021-05-27T08:54:58.625585Z","shell.execute_reply.started":"2021-05-27T08:54:57.931679Z","shell.execute_reply":"2021-05-27T08:54:58.624454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_colormin=(25,50,50)\nnew_colormax=(80,255,255)\nplot_mask(p1, new_colormin, new_colormax)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:54:58.627269Z","iopub.execute_input":"2021-05-27T08:54:58.627879Z","iopub.status.idle":"2021-05-27T08:54:59.307929Z","shell.execute_reply.started":"2021-05-27T08:54:58.627794Z","shell.execute_reply":"2021-05-27T08:54:59.30686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def segmented(image):\n    foto = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    hsv_foto = cv2.cvtColor(foto, cv2.COLOR_RGB2HSV)\n    #print(\"hsvh\",hsv_foto.dtype)\n    colormin=(25,50,50)\n    colormax=(86,255,255)\n\n    mask = cv2.inRange(hsv_foto, colormin , colormax)\n    #print(\"mask\",mask.dtype)\n    result = cv2.bitwise_and(foto, foto, mask=mask)\n    #print(\"result\",result.dtype)\n    pil_image= Image.fromarray(result)\n\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:54:59.309596Z","iopub.execute_input":"2021-05-27T08:54:59.310177Z","iopub.status.idle":"2021-05-27T08:54:59.3198Z","shell.execute_reply.started":"2021-05-27T08:54:59.310106Z","shell.execute_reply":"2021-05-27T08:54:59.318745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,10))\n\nfor n in range(12):\n        folder = subfolders[n]\n        plt.subplot(3,4,n+1)\n        files = listdir(Directory + folder + \"/\") \n        image=cv2.imread(Directory + folder + \"/\" + files[n+221])\n        plt.imshow(segmented(image))\n        plt.axis(\"off\")\n        plt.title(folder, weight='bold', fontsize=14)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-27T08:54:59.321467Z","iopub.execute_input":"2021-05-27T08:54:59.322039Z","iopub.status.idle":"2021-05-27T08:55:00.424596Z","shell.execute_reply.started":"2021-05-27T08:54:59.321975Z","shell.execute_reply":"2021-05-27T08:55:00.4236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def segmented2(image):\n    image=np.array(image)\n    #foto=image.copy().astype(np.uint8)\n    #foto = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    hsv_foto = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n    colormin=(25,50,50)\n    colormax=(90,255,255)\n    mask = cv2.inRange(hsv_foto, colormin , colormax)\n    \n    #result = cv2.bitwise_and(foto, foto, mask=mask)\n    result = cv2.bitwise_and(image, image, mask=mask)\n    result2=np.array(result)\n    #pil_image= Image.fromarray(result, mode='RGB')\n    #pil_image= Image.fromarray(result)\n\n\n    return result2","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-27T08:55:00.426167Z","iopub.execute_input":"2021-05-27T08:55:00.426679Z","iopub.status.idle":"2021-05-27T08:55:00.434585Z","shell.execute_reply.started":"2021-05-27T08:55:00.426392Z","shell.execute_reply":"2021-05-27T08:55:00.433535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        validation_split=0.2,\n        #preprocessing_function = segmented2\n                     )\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    '../input/v2-plant-seedlings-dataset/nonsegmentedv2',\n        target_size=(64,64),\n        batch_size=32,\n        class_mode='categorical',\n        subset='training')\n\nvalidation_generator = train_datagen.flow_from_directory(\n        '../input/v2-plant-seedlings-dataset/nonsegmentedv2',\n        target_size=(64, 64),\n        batch_size=32,\n        class_mode='categorical',\n        subset='validation')","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:55:00.436105Z","iopub.execute_input":"2021-05-27T08:55:00.43637Z","iopub.status.idle":"2021-05-27T08:55:01.081462Z","shell.execute_reply.started":"2021-05-27T08:55:00.436326Z","shell.execute_reply":"2021-05-27T08:55:01.080563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#x,y = train_generator.next()\n#for i in range(0,2):\n#    image = x[i]\n#    plt.imshow(image)\n#    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-27T08:55:01.082765Z","iopub.execute_input":"2021-05-27T08:55:01.083038Z","iopub.status.idle":"2021-05-27T08:55:01.088955Z","shell.execute_reply.started":"2021-05-27T08:55:01.083002Z","shell.execute_reply":"2021-05-27T08:55:01.08637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#weights_incv3 = '../input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# load pre-trained weights and add global average pooling layer\n#base_model_incv3 = InceptionV3(weights=weights_incv3, input_shape=(150,150,3), include_top=False, pooling='avg')\n\n# freeze convolutional layers\n#for layer in base_model_incv3.layers:\n#    layer.trainable = False\n\n#define classification layers\n#x = Dense(1024, activation='relu')(base_model_incv3.output)\n#predictions = Dense(1, activation='sigmoid')(x)\n#x = Dense(256, activation='relu')(base_model_incv3.output)\n#x = Dropout(0.5)(x)\n#predictions = Dense(12, activation='softmax')(x)\n\n#model = Model(inputs=base_model_incv3.input, outputs=predictions)\n#print(model.summary())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-27T08:55:01.090402Z","iopub.execute_input":"2021-05-27T08:55:01.090676Z","iopub.status.idle":"2021-05-27T08:55:01.103412Z","shell.execute_reply.started":"2021-05-27T08:55:01.090631Z","shell.execute_reply":"2021-05-27T08:55:01.102309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.layers import Dropout\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\n\nvgg_conv = VGG16(weights=None, include_top=False, input_shape=(64, 64, 3))\nvgg_conv.load_weights('../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\nfor layer in vgg_conv.layers[:-4]:\n    layer.trainable = False\n\nmodel = Sequential()\nmodel.add(vgg_conv)\n \nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(12, activation='softmax'))\n \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:55:01.104783Z","iopub.execute_input":"2021-05-27T08:55:01.105139Z","iopub.status.idle":"2021-05-27T08:55:03.337688Z","shell.execute_reply.started":"2021-05-27T08:55:01.105085Z","shell.execute_reply":"2021-05-27T08:55:03.336605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(Adam(lr=0.0001), loss='categorical_crossentropy', \n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:55:03.339346Z","iopub.execute_input":"2021-05-27T08:55:03.339765Z","iopub.status.idle":"2021-05-27T08:55:03.398454Z","shell.execute_reply.started":"2021-05-27T08:55:03.339691Z","shell.execute_reply":"2021-05-27T08:55:03.397273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We'll stop training if no improvement after some epochs\nearlystopper1 = EarlyStopping(monitor='loss', patience=10, verbose=1)\n\n# Save the best model during the traning\ncheckpointer1 = ModelCheckpoint('best_model1.hdf5'\n                                ,monitor='val_accuracy'\n                                ,verbose=1\n                                ,save_best_only=True\n                                ,save_weights_only=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T08:55:03.400321Z","iopub.execute_input":"2021-05-27T08:55:03.400746Z","iopub.status.idle":"2021-05-27T08:55:03.406833Z","shell.execute_reply.started":"2021-05-27T08:55:03.400573Z","shell.execute_reply":"2021-05-27T08:55:03.405495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(train_generator, steps_per_epoch=800, \n                    validation_data=validation_generator,\n                    validation_steps=128,\n                    epochs=15, verbose=1,\n                   callbacks=[checkpointer1])","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-05-27T08:55:03.409139Z","iopub.execute_input":"2021-05-27T08:55:03.409755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use('seaborn')\nsns.set_style('whitegrid')\nfig = plt.figure(figsize=(15,10))\n#First Model\nax1 = plt.subplot2grid((2,2),(0,0))\ntrain_loss = history.history['loss']\ntest_loss = history.history['val_loss']\nx = list(range(1, len(test_loss) + 1))\nplt.plot(x, test_loss, color = 'cyan', label = 'Test loss')\nplt.plot(x, train_loss, label = 'Training losss')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Model 1: Loss vs. Epoch',weight='bold', fontsize=18)\nax1 = plt.subplot2grid((2,2),(0,1))\ntrain_acc = history.history['accuracy']\ntest_acc = history.history['val_accuracy']\nx = list(range(1, len(test_acc) + 1))\nplt.plot(x, test_acc, color = 'cyan', label = 'Test accuracy')\nplt.plot(x, train_acc, label = 'Training accuracy')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Model 1: Accuracy vs. Epoch', weight='bold', fontsize=18)\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]}]}